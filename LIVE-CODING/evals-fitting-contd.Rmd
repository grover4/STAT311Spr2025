---
title: "Rate my Prof: Multiple Linear Regression"
subtitle: "STAT 311"
author: "Your Name Here"
date: "`r Sys.Date()`"
output: html_document
---


We return to the `evals` dataframe from the **openintro** package to fit more models to the course evaluation `score`.  We will work with the **tidyverse**, **tidymodels** and the **openintro** packages as before. We will also use the `**GGally** package for making pairwise scatter plots. 


Run the code chunk below to load the packages. Then load the data into your Environment.


```{r setup, include = FALSE}
#load packages and set global options 

library(tidyverse)     #umbrella package 
library(openintro)     #for the data
library(tidymodels)    #for model fitting/model comparison   
library(GGally)        #pairwise scatterplots

```



## Exercises 

Let's return to the `evals` data in the **openintro** package and fit a few additional models for predicting the course evaluation ratings. Our focus is on interpreting the model equations. The key thing to note is that model building is a process, and you should be willing to explore and try different things. 

The explanatory variables in this data set are either numerical or categorical and are of two types as shown below.

 - prof characteristics: `rank`, `ethnicity`, `gender`, `age`,  `bty_avg`
 
 - class characteristics: `cls_perc_eval`,  `cls_profs`, `cls_level`, `cls_credits`
 
A reasonable strategy for manually building a model to predict course evaluation `scores` is to pick a couple of numerical predictors and one categorical predictor. 

In this part, we will examine the numerical predictors first to identify a couple that seem relevant. Then we will turn to finding a categorical predictor.

### Exercise 1

Use `ggpairs` to make a scatter plot matrix of `score` versus the numeric predictors:  `age`, `bty_avg`, `cls_perc_eval`. 


We can also make a correlation heat map from the **corrplot** package using the code shown below. Attach the package in the setup code chunk, then remove the chunk option `eval = FALSE` before knitting to execute the code below.

```{r corr-heat-map, eval = FALSE}

mycorr <- evals %>% 
  select(age, bty_avg, cls_perc_eval,  score) %>% 
   cor(use="complete.obs")

corrplot(mycorr)
```

The plots don't show very strong relationships which is consistent with our conclusions from last week. Let's just pick `bty_avg` and `cls_perc_eval` as our numeric variables. They have slightly higher correlations with score (0.18) compared to age (-0.11). Also, `age` is somewhat correlated with `bty_avg`, so there is no need to have both in the model.

### Exercise 2

Fit a main effects model `model1` to predict `score` from `bty_avg` and `cls_perc_eval`. 

- Present the output in a tidy format and write the equation of the fitted model. Interpret the coefficients.
   
- Assess goodness of fit of `model1` by calculating the adjusted R-square. Save this number in a variable called `model1_rsq` and report it within a complete sentence using inline code.
   
   
Now, let us turn our attention to adding a categorical predictor `cls_level` into our model equation.



### Exercise 3

Make a visualization of `score` versus  `cls_level`. (You can also calculate grouped numerical summaries of `score` by `cls_level`)


### Exercise 4

Fit a main effects model `model2` to predict  `score` from `bty_avg`, `cls_perc_eval` and `cls_level`. 

- Present the output in a tidy format and write the equation of the fitted model.
   
- Assess goodness of fit of `model2` by calculating the adjusted R-square. Save this number in a variable called `model2_rsq` and report it within a complete sentence using inline code.
   



Add the adjusted R-suare (as a percentage and rounded to 2 digits) for `model1` and `model2`in the table below for easy comparison.

| Model     | Adjusted R square
|:----      | :------------    
| `model1`  | 
| `model2`  | 



***YOUR TURN***


Let us now consider `rank` as a possible predictor of `score`. Notice that it has three levels: teaching, tenured and tenure track.

### Exercise 5

Using an ifelse statement, create and add a new variable called `rank_bin` which combines the tenure and tenure track faculty into one category called "research". Be sure to add it your `evals` dataframe.


### Exercise 6

Make a visualization `score` versus  `rank_bin`. (You can also calculate grouped numerical summaries of `score` by `rank_bin`)


### Exercise 7

Fit a main effects model `model3` to predict  `score` from `bty_avg`, `cls_perc_eval` and `rank_bin`. 

- Present the output in a tidy format and write the equation of the fitted model. Interpret the coefficients.
   
- Assess goodness of fit by calculating the adjusted R-square. Save this in a variable called `model3_rsq` and report it within a complete sentence using inline code.
    




## Acknowledgment

This activity is from Data Science in a Box